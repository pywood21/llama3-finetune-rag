{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    model_id: str = \"meta-llama/Meta-Llama-3-8B\"\n",
    "    load_in_4bit: bool = True\n",
    "    bnb_4bit_use_double_quant: bool = True\n",
    "    bnb_4bit_quant_type: str = \"nf4\"\n",
    "    bnb_4bit_compute_dtype: str = \"float16\"  # use \"bfloat16\" if your GPU supports BF16\n",
    "    device_map: str = \"auto\"\n",
    "    use_safetensors: bool = True\n",
    "    low_cpu_mem_usage: bool = True\n",
    "    trust_remote_code: bool = False\n",
    "    padding_side: str = \"right\"\n",
    "\n",
    "@dataclass\n",
    "class LoRAConfigLite:\n",
    "    r: int = 32\n",
    "    lora_alpha: int = 64\n",
    "    lora_dropout: float = 0.05\n",
    "    bias: str = \"none\"\n",
    "    task_type: str = \"CAUSAL_LM\"\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    train_path: str = \"<PATH-TO>/finetune_data.jsonl\"  # user should provide a valid path\n",
    "    text_field: str = \"text\"\n",
    "    max_length: int = 1024\n",
    "    add_eos_token: bool = True\n",
    "    test_size: float = 0.1\n",
    "    seed: int = 27\n",
    "    num_proc: Optional[int] = None  # set e.g., 4 on Linux; keep None on Windows/Jupyter\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    output_dir: str = \"outputs/llama3_finetuned\"\n",
    "    logging_dir: str = \"outputs/logs\"\n",
    "    per_device_train_batch_size: int = 2\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    num_train_epochs: int = 5\n",
    "    logging_steps: int = 100\n",
    "    save_steps: int = 500\n",
    "    eval_steps: int = 500\n",
    "    save_total_limit: int = 3\n",
    "    fp16: bool = True  # set bf16=True if supported and desired\n",
    "    optim: str = \"paged_adamw_8bit\"\n",
    "    lr_scheduler_type: str = \"cosine\"\n",
    "    learning_rate: float = 1e-4\n",
    "    warmup_ratio: float = 0.1\n",
    "    weight_decay: float = 0.01\n",
    "    report_to: str = \"tensorboard\"\n",
    "    load_best_model_at_end: bool = True\n",
    "    metric_for_best_model: str = \"loss\"\n",
    "    greater_is_better: bool = False\n",
    "    seed: int = 27\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
