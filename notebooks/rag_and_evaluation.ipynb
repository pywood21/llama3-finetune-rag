{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd5663c",
   "metadata": {},
   "source": [
    "Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers accelerate peft datasets bitsandbytes sentence-transformers faiss-cpu \\\n",
    "#    nltk rouge-score bert-score pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa6946",
   "metadata": {},
   "source": [
    "Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceacb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, torch\n",
    "from src.rag_config import Paths, Models, RetrieverCfg, GenCfg, Flags, Experiment\n",
    "from src.seed_utils import set_all_seeds\n",
    "from src.io_utils import ensure_dir, atomic_csv_save, jsonl_write\n",
    "from src.models import load_backbone, merge_lora\n",
    "from src.prompt import build_messages\n",
    "from src.retriever import (build_corpus, make_chunks, build_or_load_embeddings,\n",
    "                           build_ip_index, retrieve_rows)\n",
    "from src.generator import safe_generate\n",
    "from src.eval_text import evaluate_text_metrics\n",
    "from src.keyword_match import covered_ratio\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "paths = Paths()\n",
    "models = Models()\n",
    "rcfg = RetrieverCfg()\n",
    "gencfg = GenCfg()\n",
    "flags = Flags()\n",
    "exp = Experiment(selected_model=\"base_rag\", seed=42)\n",
    "\n",
    "set_all_seeds(exp.seed)\n",
    "ensure_dir(paths.output_dir)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d1d72",
   "metadata": {},
   "source": [
    "Corpus → Chunks → Embeddings → Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77720f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.read_csv(paths.corpus_csv)\n",
    "df_corpus = build_corpus(df_corpus)  # ensures Authors/Year/DOI exist\n",
    "\n",
    "sbert = SentenceTransformer(models.retriever_sbert, device=device)\n",
    "hf_tok = AutoTokenizer.from_pretrained(models.retriever_sbert)\n",
    "\n",
    "df_chunks = make_chunks(df_corpus, hf_tok, max_tok=rcfg.chunk_max_tok, stride=rcfg.chunk_stride)\n",
    "embeddings, from_cache = build_or_load_embeddings(df_chunks, sbert, paths.emb_cache_npy)\n",
    "index = build_ip_index(embeddings)\n",
    "print(\"chunks:\", len(df_chunks), \"embeddings from cache:\", from_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c384f7a6",
   "metadata": {},
   "source": [
    "Load LLMs and cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c89557",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model, base_tok = load_backbone(models.base_model_id, flags.load_in_4bit, flags.use_bf16_if_available)\n",
    "ft_base_for_merge, ft_tok = load_backbone(models.base_model_id, flags.load_in_4bit, flags.use_bf16_if_available)\n",
    "ft_model = merge_lora(ft_base_for_merge, models.lora_adapter_path)\n",
    "\n",
    "cross = CrossEncoder(models.cross_encoder, device=device)\n",
    "\n",
    "model_dict = {\"base\": base_model, \"ft\": ft_model, \"base_rag\": base_model, \"ft_rag\": ft_model}\n",
    "tokenizer_dict = {\"base\": base_tok, \"ft\": ft_tok, \"base_rag\": base_tok, \"ft_rag\": ft_tok}\n",
    "print(\"loaded keys:\", list(model_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eec744",
   "metadata": {},
   "source": [
    "QA prep and generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53db00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = pd.read_csv(paths.qa_csv)\n",
    "if \"Question\" not in qa_df.columns:\n",
    "    raise KeyError(\"qa_set CSV must include a 'Question' column.\")\n",
    "questions = qa_df[\"Question\"].astype(str).fillna(\"\").tolist()\n",
    "\n",
    "model = model_dict[exp.selected_model]\n",
    "tokenizer = tokenizer_dict[exp.selected_model]\n",
    "use_rag = exp.selected_model.endswith(\"_rag\")\n",
    "\n",
    "def retriever_fn(query, k_final=rcfg.k_final, max_ctx_tokens=rcfg.max_ctx_tokens):\n",
    "    return retrieve_rows(\n",
    "        query=query,\n",
    "        faiss_index=index,\n",
    "        embeddings=embeddings,\n",
    "        df_chunks=df_chunks,\n",
    "        sbert=sbert,\n",
    "        hf_tok=hf_tok,\n",
    "        k_initial=rcfg.k_initial,\n",
    "        k_final=k_final,\n",
    "        mmr_lambda=rcfg.mmr_lambda,\n",
    "        cross_encoder=cross,\n",
    "        ce_batch_size=rcfg.ce_batch_size,\n",
    "        max_ctx_tokens=max_ctx_tokens,\n",
    "        title_max_chars=rcfg.title_max_chars,\n",
    "        excerpt_max_chars=rcfg.excerpt_max_chars\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b00e63",
   "metadata": {},
   "source": [
    "Generation loop & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "gen_txt = os.path.join(paths.output_dir, f\"generated_{exp.selected_model}_responses.txt\")\n",
    "gen_csv = os.path.join(paths.output_dir, f\"generated_{exp.selected_model}_responses.csv\")\n",
    "gen_log = os.path.join(paths.output_dir, f\"generated_{exp.selected_model}_genlog.jsonl\")\n",
    "\n",
    "records, outputs = [], []\n",
    "with open(gen_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, q in enumerate(tqdm(questions, desc=f\"Generating ({exp.selected_model})\")):\n",
    "        resp, meta = safe_generate(q, model, tokenizer, retriever_fn, use_rag, gencfg)\n",
    "        outputs.append(resp if resp is not None else \"\")\n",
    "        f.write((resp or \"\") + \"\\n\")\n",
    "        meta.update({\"idx\": i, \"model_key\": exp.selected_model, \"question_preview\": q[:160]})\n",
    "        records.append(meta)\n",
    "\n",
    "qa_save = qa_df.iloc[:len(outputs)].copy()\n",
    "qa_save[\"Generated\"] = outputs\n",
    "atomic_csv_save(qa_save, gen_csv)\n",
    "jsonl_write(records, gen_log)\n",
    "\n",
    "print(\"saved:\", gen_txt, gen_csv, gen_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bee2a",
   "metadata": {},
   "source": [
    "Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation (CosineSimilarity, BERTScore, optional Perplexity)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.eval_text import evaluate_text_metrics\n",
    "from src.io_utils import atomic_csv_save\n",
    "\n",
    "# Input from Cell 6\n",
    "eval_input = pd.read_csv(gen_csv)\n",
    "\n",
    "# Run evaluation\n",
    "# - To skip Perplexity, set ppl_model=None and ppl_tokenizer=None.\n",
    "evaluated = evaluate_text_metrics(\n",
    "    eval_input,\n",
    "    models.eval_sbert,\n",
    "    ppl_model=model,                 # optional: causal LM for perplexity\n",
    "    ppl_tokenizer=tokenizer,         # optional: tokenizer for perplexity\n",
    "    ppl_column=\"Generated\",          # \"Generated\" or \"Answer\"\n",
    "    ppl_max_ctx=gencfg.model_max_ctx # optional; None = auto\n",
    ")\n",
    "\n",
    "# Save results\n",
    "eval_csv = os.path.join(paths.output_dir, f\"metrics_{exp.selected_model}.csv\")\n",
    "atomic_csv_save(evaluated, eval_csv)\n",
    "\n",
    "print(\"metrics saved:\", eval_csv, \"| rows:\", len(evaluated))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3bb65",
   "metadata": {},
   "source": [
    "Keyword matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eee1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "dfm = pd.read_csv(eval_csv)\n",
    "kw_col = \"Keywords\" if \"Keywords\" in dfm.columns else None\n",
    "\n",
    "if kw_col:\n",
    "    km_sbert = SentenceTransformer(models.eval_sbert, device=device)\n",
    "    scores = []\n",
    "    for _, row in tqdm(dfm.iterrows(), total=len(dfm), desc=f\"Keyword Matching ({exp.selected_model})\"):\n",
    "        raw_kw = str(row.get(kw_col, \"\") or \"\")\n",
    "        gen = str(row.get(\"Generated\", \"\") or \"\")\n",
    "        keywords = [k.strip() for k in raw_kw.split(\",\") if k.strip()]\n",
    "        score = covered_ratio(keywords, gen, km_sbert)\n",
    "        scores.append(score)\n",
    "    dfm[\"Keyword_Match_Score\"] = scores\n",
    "    km_csv = os.path.join(paths.output_dir, f\"metrics_{exp.selected_model}_with_keyword.csv\")\n",
    "    atomic_csv_save(dfm, km_csv)\n",
    "    print(\"keyword metrics saved:\", km_csv)\n",
    "else:\n",
    "    print(\"no 'Keywords' column found; skipping keyword matching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b1e49",
   "metadata": {},
   "source": [
    "Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"cleanup done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db76b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
